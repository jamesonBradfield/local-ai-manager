{
  "version": "2.0.0",
  "server": {
    "host": "127.0.0.1",
    "port": 8080,
    "models_dir": "~/models",
    "cache_dir": "~/.cache/local-ai",
    "log_dir": "~/.local/log",
    "llama_server_path": "llama-server.exe",
    "default_model": "nanbeige-3b",
    "auto_start": false
  },
  "steam": {
    "enabled": true,
    "steam_logs_dir": "~/scoop/apps/steam/current/logs",
    "log_file": "gameprocess_log.txt",
    "stop_ai_on_game": true,
    "save_cache_on_stop": true,
    "restart_ai_after_game": true,
    "restore_model": null,
    "processes_to_kill": [
      "chrome",
      "msedge",
      "discord",
      "slack",
      "Teams"
    ]
  },
  "opencode": {
    "config_dir": "~/.config/opencode",
    "local_agent_name": "local",
    "cloud_agent_name": "cloud",
    "config_file": "oh-my-opencode.json"
  },
  "models": [
    {
      "id": "nanbeige-3b",
      "name": "Nanbeige 3B",
      "description": "Nanbeige 3B Q4_K_M - Fast, smart, 32K context (Primary)",
      "filename_pattern": "(?i)Nanbeige.*3B.*Q4_K_M.*\\.gguf$",
      "ctx_size": 64536,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 16384,
      "ubatch_size": 4096,
      "flash_attn": true,
      "cache_type_k": "q4_0",
      "cache_type_v": "q4_0",
      "mlock": true,
      "mmap": false,
      "cont_batching": true,
      "temperature": 0.6,
      "top_p": 0.95,
      "top_k": 40,
      "priority": 1,
      "tags": ["primary", "fast", "coding", "distilled"]
    },
    {
      "id": "qwen3-14b",
      "name": "Qwen3 14B",
      "description": "Qwen3 14B Q4_K_M - High quality, 8K context (Full VRAM)",
      "filename_pattern": "(?i)Qwen3-14B.*Q4_K_M.*\\.gguf$",
      "ctx_size": 16384,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 4096,
      "ubatch_size": 1024,
      "flash_attn": true,
      "mlock": true,
      "mmap": false,
      "cache_type_k": "q4_0",
      "cache_type_v": "q4_0",
      "cont_batching": true,
      "temperature": 0.6,
      "top_p": 0.95,
      "top_k": 40,
      "priority": 2,
      "tags": ["high-quality", "coding"]
    },
    {
      "id": "qwen2.5-7b",
      "name": "Qwen2.5 Coder 7B",
      "description": "Qwen2.5 Coder 7B Q5_K_M - Balanced, 128K context",
      "filename_pattern": "(?i)qwen2\\.5-coder-7b.*Q5_K.*\\.gguf$",
      "ctx_size": 131072,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 4096,
      "ubatch_size": 1024,
      "flash_attn": true,
      "mlock": true,
      "cache_type_k": "q4_0",
      "cache_type_v": "q4_0",
      "mmap": true,
      "cont_batching": true,
      "temperature": 0.1,
      "top_p": 0.95,
      "top_k": 40,
      "priority": 3,
      "tags": ["balanced", "coding", "legacy"]
    },
    {
      "id": "qwen2.5-14b",
      "name": "Qwen2.5 Coder 14B",
      "description": "Qwen2.5 Coder 14B Q4_K_M - High quality, 64K context",
      "filename_pattern": "(?i)qwen2\\.5-coder-14b.*Q4_K_M.*\\.gguf$",
      "ctx_size": 65536,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 4096,
      "ubatch_size": 1024,
      "flash_attn": true,
      "mlock": true,
      "mmap": true,
      "cont_batching": true,
      "temperature": 0.1,
      "top_p": 0.95,
      "top_k": 40,
      "priority": 4,
      "tags": ["high-quality", "coding", "legacy"]
    },
    {
      "id": "qwen2.5-coder-1.5b",
      "name": "Qwen2.5 Coder 1.5B (Draft)",
      "description": "Qwen2.5 Coder 1.5B Q4_K_M - Fast draft model for speculative decoding",
      "filename_pattern": "(?i)qwen2\\.5-coder-1\\.5b.*Q4_K.*\\.gguf$",
      "ctx_size": 32768,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 2048,
      "ubatch_size": 512,
      "flash_attn": true,
      "mlock": true,
      "mmap": true,
      "cont_batching": true,
      "temperature": 0.1,
      "top_p": 0.95,
      "top_k": 40,
      "priority": 5,
      "tags": ["draft", "fast", "speculative"]
    },
    {
      "id": "qwen2.5-coder-14b-spec",
      "name": "Qwen2.5 Coder 14B (Speculative)",
      "description": "Qwen2.5 Coder 14B with speculative decoding via 1.5B draft model",
      "filename_pattern": "(?i)qwen2\\.5-coder-14b.*Q4_K_M.*\\.gguf$",
      "ctx_size": 65536,
      "n_gpu_layers": 99,
      "threads": 8,
      "batch_size": 4096,
      "ubatch_size": 1024,
      "flash_attn": true,
      "mlock": true,
      "mmap": true,
      "cont_batching": true,
      "temperature": 0.1,
      "top_p": 0.95,
      "top_k": 40,
      "draft_model_id": "qwen2.5-coder-1.5b",
      "draft_n_tokens": 16,
      "draft_p_min": 0.9,
      "priority": 2,
      "tags": ["speculative", "high-quality", "coding"]
    }
  ],
  "verbose": false,
  "dry_run": false
}
